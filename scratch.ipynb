{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyoxigraph as ox\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = ox.Store(\"data/wety.db\")\n",
    "# store = ox.Store(\"data/test_output/wety.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_id(term, lang, n=0):\n",
    "    return [s['w'].value for s in store.query(f'SELECT ?w WHERE {{ ?w <p:term> \"{term}\" . ?w <p:lang> \"{lang}\" .}}')][n]\n",
    "\n",
    "def print_item_info(id):\n",
    "    results = store.query(\n",
    "        f\"\"\"SELECT ?term ?lang ?gloss WHERE {{ \n",
    "            <{id}> <p:term> ?term .\n",
    "            <{id}> <p:lang> ?lang .\n",
    "            OPTIONAL {{ <{id}> <p:gloss> ?gloss }}\n",
    "        }} LIMIT 1\"\"\"\n",
    "    )\n",
    "    for result in results:\n",
    "        print(result['term'].value)\n",
    "        print(result['lang'].value)\n",
    "        if result['gloss']: print(result['gloss'].value)\n",
    "    print()\n",
    "\n",
    "def get_item(id):\n",
    "    item = {\"id\": id}\n",
    "    results = store.query(\n",
    "        f\"\"\"SELECT ?term ?lang ?url ?pos ?gloss ?isImputed ?mode ?isReconstructed ?headProgenitor ?progenitor WHERE {{ \n",
    "            <{id}> <p:term> ?term .\n",
    "            <{id}> <p:lang> ?lang .\n",
    "            OPTIONAL {{ <{id}> <p:url> ?url }} .\n",
    "            OPTIONAL {{ <{id}> <p:pos> ?pos }} .\n",
    "            OPTIONAL {{ <{id}> <p:gloss> ?gloss }} .\n",
    "            OPTIONAL {{ <{id}> <p:isImputed> ?isImputed }} .\n",
    "            OPTIONAL {{ <{id}> <p:mode> ?mode }} .\n",
    "            OPTIONAL {{ <{id}> <p:isReconstructed> ?isReconstructed }} .\n",
    "            OPTIONAL {{ <{id}> <p:headProgenitor> ?headProgenitor }} .\n",
    "            OPTIONAL {{ <{id}> <p:progenitor> ?progenitor }} .\n",
    "        }}\"\"\"\n",
    "    )\n",
    "    preds = [\"term\", \"lang\", \"url\", \"pos\", \"gloss\", \"isImputed\", \"mode\", \"isReconstructed\", \"headProgenitor\", \"progenitor\"]\n",
    "    item = {p: None if p != \"progenitor\" else [] for p in preds} \n",
    "    for result in results:\n",
    "        for p in preds:\n",
    "            if result[p] is not None:\n",
    "                if p == \"progenitor\":\n",
    "                    item[p].append(result[p].value)\n",
    "                else:\n",
    "                    if item[p] is None:\n",
    "                        item[p] = result[p].value\n",
    "    return item\n",
    "\n",
    "# we only continue expanding items if they are in only_expand_these. if this arg is none, expand all\n",
    "def get_item_expansion(id, only_expand_these=None, terminal_lang=None):\n",
    "    item = get_item(id)\n",
    "    if item['lang'] != terminal_lang:\n",
    "        children_expansion = []\n",
    "        should_expand = (lambda id: id in only_expand_these) if only_expand_these else (lambda id: True)\n",
    "        for child in filter(should_expand, get_children(id)):\n",
    "            child_expansion = get_item_expansion(child, only_expand_these, terminal_lang)\n",
    "            children_expansion.append(child_expansion)\n",
    "        item['children'] = children_expansion\n",
    "    return item\n",
    "\n",
    "# optional lang arg restricts terminal children to first terms in lang\n",
    "def get_item_json(id, lang=None):\n",
    "    only_expand_these = get_all_lang_descendant_ancestors(id, lang) if lang else None\n",
    "    item_expansion = get_item_expansion(id, only_expand_these, lang)\n",
    "    return json.dumps(item_expansion, ensure_ascii=False, indent=True)\n",
    "\n",
    "def get_head_source(id):\n",
    "    results = store.query(\n",
    "        f\"\"\"SELECT ?source ?order ?head WHERE {{ \n",
    "            <{id}> <p:head> ?head .\n",
    "            <{id}> <p:source> ?sourceNode .\n",
    "            ?sourceNode <p:item> ?source .\n",
    "            ?sourceNode <p:order> ?order .\n",
    "        }}\"\"\"\n",
    "    )\n",
    "    # for whatever reason doing this filtering outside the query is way faster\n",
    "    # than using FILTER inside the query\n",
    "    for result in results:\n",
    "        if result['order'].value == result['head'].value:\n",
    "            return result['source'].value\n",
    "    return None\n",
    "\n",
    "def get_head_progenitor(id):\n",
    "    results = store.query(\n",
    "        f\"\"\"SELECT ?headProgenitor WHERE {{ \n",
    "            <{id}> <p:headProgenitor> ?headProgenitor .\n",
    "        }}\"\"\"\n",
    "    )\n",
    "    for result in results:\n",
    "        return result['headProgenitor'].value\n",
    "    return None\n",
    "\n",
    "def get_ancestors(id):\n",
    "    results = store.query(\n",
    "        f\"\"\"SELECT ?item WHERE {{ \n",
    "            <{id}> (<p:source>/<p:item>)+ ?item .\n",
    "        }}\"\"\"\n",
    "    )\n",
    "    items = set()\n",
    "    for result in results:\n",
    "        items.add(result['item'].value)\n",
    "    return items if items else None\n",
    "\n",
    "# get all ancestors of all items that both share the same headProgenitor and are\n",
    "# in lang\n",
    "def get_all_lang_descendant_ancestors(headProgenitor, lang):\n",
    "    results = store.query(\n",
    "        f\"\"\"SELECT ?ancestor WHERE {{ \n",
    "            ?item <p:headProgenitor> <{headProgenitor}> .\n",
    "            ?item (<p:source>/<p:item>)* ?ancestor .\n",
    "            ?item <p:lang> ?lang .\n",
    "            FILTER ( ?lang = \"{lang}\" ) .\n",
    "        }}\"\"\"\n",
    "    )\n",
    "    return {result['ancestor'].value for result in results}\n",
    "\n",
    "def get_children(id):\n",
    "    return [w['child'].value for w in store.query(\n",
    "        f\"\"\"SELECT ?child WHERE {{ \n",
    "            ?sourceNode <p:item> <{id}> .\n",
    "            ?sourceNode <p:order> ?order .\n",
    "            ?child <p:source> ?sourceNode .\n",
    "            ?child <p:head> ?order . \n",
    "        }}\"\"\"\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = get_item_id(\"mainą\", \"Proto-Germanic\", 0)\n",
    "print_item_info(item)\n",
    "head_progenitor = get_head_progenitor(item)\n",
    "print_item_info(head_progenitor)\n",
    "print_item_info(get_head_source(item))\n",
    "for child in get_children(item):\n",
    "    print_item_info(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = \"mind\"\n",
    "lang = \"English\"\n",
    "item = get_item_id(\"mind\", \"English\", 0)\n",
    "print_item_info(item)\n",
    "head_progenitor = get_head_progenitor(item)\n",
    "print_item_info(head_progenitor)\n",
    "d = get_item_json(head_progenitor, \"English\")\n",
    "with open(f\"data/test_output/{term}_{lang}.json\", 'w') as f:\n",
    "    f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "term_re = re.compile(r'wiki/(.+)%23.+')\n",
    "recon_term_re = re.compile(r'wiki/Reconstruction:(.+)%2F.+')\n",
    "\n",
    "def json_lang_terms(item_json):\n",
    "    full_item = json.loads(item_json)\n",
    "    langterms = set()\n",
    "    def recurse(item):\n",
    "        url = item[\"url\"]\n",
    "        if url:\n",
    "            m = re.search(term_re, url) or re.search(recon_term_re, url)\n",
    "            term = m.group(1)\n",
    "            langterms.add((item[\"lang\"], term))\n",
    "            if \"children\" in item: \n",
    "                for child in item[\"children\"]:\n",
    "                    recurse(child)\n",
    "    recurse(full_item)\n",
    "    return langterms\n",
    "\n",
    "\n",
    "def write_wiktextract_items(item_json):\n",
    "    lang_terms = json_lang_terms(item_json)\n",
    "    with open(\"data/data.json\", \"r\", encoding=\"utf-8\") as fin, open(\"data/test/descendants.jsonl\", \"w\") as fout:\n",
    "        for line in fin:\n",
    "            wikt = json.loads(line)\n",
    "            if \"lang\" in wikt and \"word\" in wikt and(wikt[\"lang\"], wikt[\"word\"]) in lang_terms:\n",
    "                fout.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_wiktextract_items(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = get_item_id(\"munaną\", \"Proto-Germanic\", 0)\n",
    "print(get_item_json(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    [[w['lang'].value, w['pos'].value, w['term'].value] for w in store.query(\n",
    "        f\"\"\"SELECT DISTINCT ?lang ?pos ?term WHERE {{ \n",
    "            ?item <p:glossNum> ?glossNum .\n",
    "            ?item <p:glossNum> ?glossNum .\n",
    "            ?item <p:lang> ?lang .\n",
    "            ?item <p:pos> ?pos .\n",
    "            ?item <p:term> ?term .\n",
    "        }}\"\"\"\n",
    "    )],\n",
    "    columns=[\"lang\", \"pos\", \"term\"]\n",
    ")\n",
    "data.sort_values([\"lang\", \"pos\", \"term\"], inplace=True)\n",
    "data.to_csv(\"data/nonzero_glossNum.csv\", index=False)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    [[w['lang'].value, w['pos'].value, w['term'].value] for w in store.query(\n",
    "        f\"\"\"SELECT DISTINCT ?lang ?pos ?term WHERE {{ \n",
    "            ?item <p:glossNum> ?glossNum .\n",
    "            ?item <p:etyNum> ?etyNum .\n",
    "            ?item <p:lang> ?lang .\n",
    "            ?item <p:pos> ?pos .\n",
    "            ?item <p:term> ?term .\n",
    "        }}\"\"\"\n",
    "    )],\n",
    "    columns=[\"lang\", \"pos\", \"term\"]\n",
    ")\n",
    "data.sort_values([\"lang\", \"pos\", \"term\"], inplace=True)\n",
    "data.to_csv(\"data/nonzero_glossNum_and_etyNum.csv\", index=False)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"data/descendants_langs.csv\", names=[\"lang\",\"n\"])\n",
    "d[\"n\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fas = pd.read_csv(\"data/feedback_arc_set_pass_1.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1df8d05a25a6f469907ddd1e2bb3a6553cf98e476e07b1efbb7c7c485afc0773"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
